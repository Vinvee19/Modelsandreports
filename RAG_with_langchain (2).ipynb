{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Uakr9cGivYD",
    "outputId": "1c540ab2-6421-4850-f7aa-60e4c993e55f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: astrapy in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
      "Requirement already satisfied: deprecation<2.2.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from astrapy) (2.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]<1,>=0.25.2->astrapy) (0.28.1)\n",
      "Requirement already satisfied: pymongo>=3 in /usr/local/lib/python3.11/dist-packages (from astrapy) (4.11.2)\n",
      "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.11/dist-packages (from astrapy) (0.10.2)\n",
      "Requirement already satisfied: uuid6>=2024.1.12 in /usr/local/lib/python3.11/dist-packages (from astrapy) (2024.7.10)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation<2.2.0,>=2.1.0->astrapy) (24.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]<1,>=0.25.2->astrapy) (4.2.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo>=3->astrapy) (2.7.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy) (4.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install astrapy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sb25zmijmD1A",
    "outputId": "ab843c9d-2b34-40c4-ab3b-a594bc476b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
      "Collecting langchain_astradb\n",
      "  Downloading langchain_astradb-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting cassio\n",
      "  Downloading cassio-0.1.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.35 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.40)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: astrapy<2.0.0,>=1.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain_astradb) (1.5.2)\n",
      "Collecting langchain-community>=0.3.1 (from langchain_astradb)\n",
      "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting cassandra-driver<4.0.0,>=3.28.0 (from cassio)\n",
      "  Downloading cassandra_driver-3.29.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: deprecation<2.2.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from astrapy<2.0.0,>=1.5.2->langchain_astradb) (2.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain_astradb) (0.28.1)\n",
      "Requirement already satisfied: pymongo>=3 in /usr/local/lib/python3.11/dist-packages (from astrapy<2.0.0,>=1.5.2->langchain_astradb) (4.11.2)\n",
      "Requirement already satisfied: toml<0.11.0,>=0.10.2 in /usr/local/lib/python3.11/dist-packages (from astrapy<2.0.0,>=1.5.2->langchain_astradb) (0.10.2)\n",
      "Requirement already satisfied: uuid6>=2024.1.12 in /usr/local/lib/python3.11/dist-packages (from astrapy<2.0.0,>=1.5.2->langchain_astradb) (2024.7.10)\n",
      "Collecting geomet<0.3,>=0.1 (from cassandra-driver<4.0.0,>=3.28.0->cassio)\n",
      "  Downloading geomet-0.2.1.post1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Collecting langchain-core<1.0.0,>=0.3.35 (from langchain)\n",
      "  Downloading langchain_core-0.3.41-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community>=0.3.1->langchain_astradb)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community>=0.3.1->langchain_astradb)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community>=0.3.1->langchain_astradb)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.1->langchain_astradb)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.1->langchain_astradb)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (8.1.8)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (1.17.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain_astradb) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain_astradb) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain_astradb) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain_astradb) (4.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain) (3.0.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community>=0.3.1->langchain_astradb)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo>=3->astrapy<2.0.0,>=1.5.2->langchain_astradb) (2.7.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain_astradb) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain_astradb) (4.1.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community>=0.3.1->langchain_astradb)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.2->httpx[http2]<1,>=0.25.2->astrapy<2.0.0,>=1.5.2->langchain_astradb) (1.3.1)\n",
      "Downloading langchain_astradb-0.5.3-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.7/58.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cassio-0.1.10-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cassandra_driver-3.29.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.41-py3-none-any.whl (415 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: xxhash, python-dotenv, mypy-extensions, marshmallow, httpx-sse, geomet, dill, typing-inspect, multiprocess, cassandra-driver, pydantic-settings, dataclasses-json, cassio, langchain-core, datasets, langchain, langchain-community, langchain_astradb\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.40\n",
      "    Uninstalling langchain-core-0.3.40:\n",
      "      Successfully uninstalled langchain-core-0.3.40\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.19\n",
      "    Uninstalling langchain-0.3.19:\n",
      "      Successfully uninstalled langchain-0.3.19\n",
      "Successfully installed cassandra-driver-3.29.2 cassio-0.1.10 dataclasses-json-0.6.7 datasets-3.3.2 dill-0.3.8 geomet-0.2.1.post1 httpx-sse-0.4.0 langchain-0.3.20 langchain-community-0.3.19 langchain-core-0.3.41 langchain_astradb-0.5.3 marshmallow-3.26.1 multiprocess-0.70.16 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.0.1 typing-inspect-0.9.0 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain_astradb cassio datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_YsNkP2ixGN",
    "outputId": "76ed04f2-7882-4b0e-a50a-f92954e22a56"
   },
   "source": [
    "from astrapy import DataAPIClient\n",
    "\n",
    "# Initialize the client\n",
    "client = DataAPIClient(\"********************************\")\n",
    "db = client.get_database_by_api_endpoint(\n",
    "  \"*************************************\"\n",
    ")\n",
    "\n",
    "print(f\"Connected to Astra DB: {db.list_collection_names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXTC7ydWjpic"
   },
   "outputs": [],
   "source": [
    "# Install libraries such as cassio, datasets, langchain, openai, tiktoken\n",
    "# !pip install -q cassio datasets langchain openai tiktoken\n",
    "# pip install  langchain-astradb>=0.0.1\n",
    "\n",
    "import langchain\n",
    "\n",
    "# Import the following from langchain\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper # All vectors will be wrapped as one package\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings # We will use Open AI embeddings to convert text into Vectors...\n",
    "\n",
    "# Dataset retrieval using HuggingFace\n",
    "from datasets import load_dataset\n",
    "\n",
    "# CassIO helps integrate the AstraDB with the Langchain\n",
    "import cassio\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import os\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hew4zXJYlEyI",
    "outputId": "5eab8b7a-5abb-4e74-8213-291094b35400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
      "Collecting openai\n",
      "  Downloading openai-1.65.4-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.41)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.20)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.11)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community) (0.3.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading openai-1.65.4-py3-none-any.whl (473 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.5/473.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.61.1\n",
      "    Uninstalling openai-1.61.1:\n",
      "      Successfully uninstalled openai-1.61.1\n",
      "Successfully installed openai-1.65.4\n"
     ]
    }
   ],
   "source": [
    "pip install openai -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JpudSXaxmxDH",
    "outputId": "15f60e11-0386-445f-8d7f-e5e756b944dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCYNdkXKm_A_"
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KjQ8XfFcnSkV",
    "outputId": "97a6a549-dd50-4c74-fb6e-6504a466e214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your api:··········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "api_key=getpass.getpass('Enter your api:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRSbMnMMne1n"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "openai.api_key = api_key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fucLBV2cn7t5",
    "outputId": "a49bb26a-6143-4df5-ce64-73e0163e8c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your astra db api key:··········\n",
      "Enter your astra db end point:··········\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import AstraDB\n",
    "from langchain.schema import Document\n",
    "\n",
    "ASTRA_DB_TOKEN = getpass.getpass('Enter your astra db api key:')\n",
    "ASTRA_DB_API_ENDPOINT=getpass.getpass('Enter your astra db end point:')\n",
    "embeddings=OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-MkoO-uoaQe"
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(page_content=\"The Eiffel Tower is in Paris.\"),\n",
    "    Document(page_content=\"Einstein developed the theory of relativity.\"),\n",
    "    Document(page_content=\"Python is a popular programming language.\"),\n",
    "    Document(page_content=\"RAG enhances LLMs by retrieving external data.\")\n",
    "]\n",
    "\n",
    "# Store the docs in AstraDB\n",
    "vector_store = AstraDB.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"my_vector_store\",\n",
    "    token=ASTRA_DB_TOKEN,\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYl4jJsBpWpe",
    "outputId": "1238678f-4a0b-4625-95e5-fd39fd1a35db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ncSLpNi-pSeF",
    "outputId": "6239851d-6529-492e-e7aa-4f41c59c36a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 : The Eiffel Tower is in Paris.\n"
     ]
    }
   ],
   "source": [
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "query = \"Where is the Eiffel Tower?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "retrieved_docs\n",
    "\n",
    "for idx, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Document {idx+1} : {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMcwyjhipx9Z"
   },
   "outputs": [],
   "source": [
    "# Read the pdf\n",
    "pdf = PdfReader(\"Gita.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqMMDoTCqZDX"
   },
   "outputs": [],
   "source": [
    "# Saving the entire pdf as a raw_text\n",
    "from typing_extensions import Concatenate\n",
    "\n",
    "raw_text = ' '\n",
    "for i, page in enumerate(pdf.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text +=content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtsBuHw8qvib"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from astrapy.db import AstraDB\n",
    "\n",
    "ASTRA_DB_APPLICATION_TOKEN=\"AstraCS:yHzOIWzScOxtmuYKBbjCwsxO:36355dc0df897a4e0bdf34bff6394bf502b5d98af02d714a6e41c6b5782ba6b3\"\n",
    "ASTRA_DB_ID = \"64a27ab1-e548-46be-8fe1-72b9661f7ccb\"\n",
    "OPEN_API_KEY = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0D1MUk9Vq0da"
   },
   "outputs": [],
   "source": [
    "# Establish connection with db\n",
    "cassio.init(token = ASTRA_DB_APPLICATION_TOKEN, database_id = ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ml-DrLutBj_"
   },
   "outputs": [],
   "source": [
    "\n",
    "llm = OpenAI(openai_api_key = OPEN_API_KEY)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key = OPEN_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXFvu7Fyu9rF"
   },
   "outputs": [],
   "source": [
    "# Create the LangChain Vector Store backed by AstraDB\n",
    "astra_vector_store = Cassandra(embedding=embeddings,\n",
    "                              table_name=\"qa_mini_demo\",\n",
    "                              session = None, keyspace = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIr2YfAAvBv_"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(separator = \"\\n\",\n",
    "                                     chunk_size = 1500,\n",
    "                                     chunk_overlap = 200,\n",
    "                                     length_function = len)\n",
    "\n",
    "# Converting the Data into Chunks\n",
    "text = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPQEMYZvvFgj"
   },
   "outputs": [],
   "source": [
    "# Add text into cassandra db\n",
    "astra_vector_store.add_texts(text)\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore = astra_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mni-1cCgvI9U",
    "outputId": "c80ebb0c-54ca-4501-c8be-242f750dcb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or type 'quit' to exit): What is the Objective?\n",
      "\n",
      "QUESTION: \"What is the Objective?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER: \"The objective of this case study is to explore how to implement Retrieval-Augmented Generation (RAG) using LangChain and AstraDB, and to equip learners with the skills to build advanced and efficient AI systems that leverage external data for improved performance.\"\n",
      "\n",
      "FIRST DOCUMENTS BY RELEVANCE:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [0.8559] \"RAG\n",
      "with\n",
      "LangChain\n",
      "Day\n",
      "5\n",
      "Case\n",
      "Study:\n",
      "Learner\n",
      "Guide\n",
      "Objective\n",
      "In\n",
      "this\n",
      "case\n",
      "study,\n",
      "we\n",
      "will\n",
      "explore\n",
      "how\n",
      "to\n",
      "implement\n",
      "Retrieval-Augmented\n",
      "Generation\n",
      "(RAG)\n",
      "using\n",
      "LangChain,\n",
      "a\n",
      "powerful\n",
      "tool\n",
      "that\n",
      "integrates\n",
      "with\n",
      "AstraDB\n",
      "to\n",
      "enhance\n",
      "the\n",
      "capabilities\n",
      "of\n",
      "language\n",
      "models\n",
      "by\n",
      "incorporating\n",
      "external\n",
      "data.\n",
      "We\n",
      "will\n",
      "use\n",
      "OpenAI\n",
      "embeddings\n",
      "to\n",
      "convert\n",
      "text\n",
      "into\n",
      "vectors\n",
      "and\n",
      "leverage\n",
      "a\n",
      "vector\n",
      "store\n",
      "backed\n",
      "by\n",
      "AstraDB\n",
      "to\n",
      "store\n",
      "and\n",
      "query\n",
      "these\n",
      "vectors.\n",
      "Learning\n",
      "Outcomes:\n",
      "By\n",
      "the\n",
      "end\n",
      "of\n",
      "this\n",
      "case\n",
      "study,\n",
      "learners\n",
      "will\n",
      "be\n",
      "able\n",
      "to:\n",
      "●\n",
      "Understand\n",
      "the\n",
      "concept\n",
      "of\n",
      "Retrieval-Augmented\n",
      "Generation\n",
      "(RAG)\n",
      "and\n",
      "its\n",
      "applications.\n",
      "●\n",
      "Set\n",
      "up\n",
      "and\n",
      "conﬁgure\n",
      "LangChain\n",
      "with\n",
      "AstraDB\n",
      "for\n",
      "efﬁcient\n",
      "data\n",
      "retrieval\n",
      "and\n",
      "storage.\n",
      "●\n",
      "Implement\n",
      "a\n",
      "complete\n",
      "workﬂow\n",
      "to\n",
      "process\n",
      "documents,\n",
      "convert\n",
      "them\n",
      "into\n",
      "embeddings,\n",
      "and\n",
      "store\n",
      "them\n",
      "in\n",
      "a\n",
      "vector\n",
      "database.\n",
      "●\n",
      "Perform\n",
      "queries\n",
      "against\n",
      "the\n",
      "vector\n",
      "database\n",
      "and\n",
      "integrate\n",
      "the\n",
      "results\n",
      "with\n",
      "a\n",
      "language\n",
      "model\n",
      "to\n",
      "generate\n",
      "answers.\n",
      "Case\n",
      "Study\n",
      "Outline:\n",
      "Introduction\n",
      "to\n",
      "RAG\n",
      "and\n",
      "LangChain\n",
      "○\n",
      "Overview\n",
      "of\n",
      "RAG\n",
      "and\n",
      "its\n",
      "beneﬁ ...\"\n",
      "    [0.8545] \"and\n",
      "contextually\n",
      "relevant\n",
      "responses.\n",
      "By\n",
      "completing\n",
      "this\n",
      "case\n",
      "study,\n",
      "you\n",
      "now\n",
      "have\n",
      "hands-on\n",
      "experience\n",
      "with\n",
      "the\n",
      "end-to-end\n",
      "process\n",
      "of\n",
      "setting\n",
      "up\n",
      "a\n",
      "RAG\n",
      "system\n",
      "using\n",
      "LangChain\n",
      "and\n",
      "AstraDB.\n",
      "This\n",
      "knowledge\n",
      "equips\n",
      "you\n",
      "with\n",
      "the\n",
      "skills\n",
      "to\n",
      "build\n",
      "more\n",
      "advanced\n",
      "and\n",
      "efﬁcient\n",
      "AI\n",
      "systems\n",
      "that\n",
      "leverage\n",
      "external\n",
      "data\n",
      "for\n",
      "improved\n",
      "performance.\n",
      "Proprietary\n",
      "content.\n",
      "©\n",
      "Great\n",
      "Learning.\n",
      "All\n",
      "Rights\n",
      "Reserved.\n",
      "Unauthorized\n",
      "use\n",
      "or\n",
      "distribution\n",
      "prohibited.\n",
      "3\n",
      "vinothiniveerasekar@gmail.com\n",
      "EGRWOTNAD8\n",
      "This file is meant for personal use by vinothiniveerasekar@gmail.com only.\n",
      "Sharing or publishing the contents in part or full is liable for legal action. ...\"\n",
      "    [0.8463] \"●\n",
      "Setting\n",
      "Up\n",
      "LangChain\n",
      "and\n",
      "AstraDB:\n",
      "You\n",
      "successfully\n",
      "installed\n",
      "and\n",
      "conﬁgured\n",
      "the\n",
      "necessary\n",
      "libraries\n",
      "and\n",
      "established\n",
      "a\n",
      "connection\n",
      "with\n",
      "AstraDB\n",
      "using\n",
      "Cassio.\n",
      "This\n",
      "setup\n",
      "is\n",
      "crucial\n",
      "for\n",
      "managing\n",
      "and\n",
      "retrieving\n",
      "large-scale\n",
      "data\n",
      "efﬁciently.\n",
      "Proprietary\n",
      "content.\n",
      "©\n",
      "Great\n",
      "Learning.\n",
      "All\n",
      "Rights\n",
      "Reserved.\n",
      "Unauthorized\n",
      "use\n",
      "or\n",
      "distribution\n",
      "prohibited.\n",
      "2\n",
      "vinothiniveerasekar@gmail.com\n",
      "EGRWOTNAD8\n",
      "This file is meant for personal use by vinothiniveerasekar@gmail.com only.\n",
      "Sharing or publishing the contents in part or full is liable for legal action.\n",
      "●\n",
      "Data\n",
      "Processing:\n",
      "You\n",
      "practiced\n",
      "loading\n",
      "and\n",
      "extracting\n",
      "text\n",
      "data\n",
      "from\n",
      "a\n",
      "PDF\n",
      "document,\n",
      "converting\n",
      "it\n",
      "into\n",
      "embeddings\n",
      "using\n",
      "OpenAI,\n",
      "and\n",
      "storing\n",
      "these\n",
      "embeddings\n",
      "in\n",
      "a\n",
      "vector\n",
      "store\n",
      "backed\n",
      "by\n",
      "AstraDB.\n",
      "This\n",
      "process\n",
      "is\n",
      "fundamental\n",
      "for\n",
      "preparing\n",
      "data\n",
      "to\n",
      "be\n",
      "used\n",
      "in\n",
      "RAG.\n",
      "●\n",
      "Implementing\n",
      "Vector\n",
      "Stores:\n",
      "You\n",
      "created\n",
      "a\n",
      "LangChain\n",
      "vector\n",
      "store\n",
      "and\n",
      "wrapped\n",
      "it\n",
      "in\n",
      "a\n",
      "VectorStoreIndexWrapper,\n",
      "allowing\n",
      "for\n",
      "efﬁcient\n",
      "querying\n",
      "and\n",
      "retrieval\n",
      "of\n",
      "relevant\n",
      "documents\n",
      "based\n",
      "on\n",
      "user\n",
      "querie ...\"\n",
      "    [0.8452] \"Great\n",
      "Learning.\n",
      "All\n",
      "Rights\n",
      "Reserved.\n",
      "Unauthorized\n",
      "use\n",
      "or\n",
      "distribution\n",
      "prohibited.\n",
      "1\n",
      "vinothiniveerasekar@gmail.com\n",
      "EGRWOTNAD8\n",
      "This file is meant for personal use by vinothiniveerasekar@gmail.com only.\n",
      "Sharing or publishing the contents in part or full is liable for legal action.\n",
      "Data\n",
      "Retrieval\n",
      "and\n",
      "Preprocessing\n",
      "○\n",
      "Loading\n",
      "a\n",
      "dataset\n",
      "using\n",
      "HuggingFace.\n",
      "○\n",
      "Reading\n",
      "and\n",
      "extracting\n",
      "text\n",
      "from\n",
      "a\n",
      "PDF\n",
      "document.\n",
      "Connecting\n",
      "to\n",
      "AstraDB\n",
      "○\n",
      "Establishing\n",
      "a\n",
      "connection\n",
      "with\n",
      "AstraDB\n",
      "using\n",
      "Cassio.\n",
      "○\n",
      "Conﬁguring\n",
      "database\n",
      "credentials\n",
      "and\n",
      "tokens.\n",
      "Embedding\n",
      "and\n",
      "Storing\n",
      "Data\n",
      "○\n",
      "Creating\n",
      "LangChain\n",
      "embeddings\n",
      "using\n",
      "OpenAI.\n",
      "○\n",
      "Setting\n",
      "up\n",
      "a\n",
      "LangChain\n",
      "vector\n",
      "store\n",
      "backed\n",
      "by\n",
      "AstraDB.\n",
      "○\n",
      "Splitting\n",
      "text\n",
      "into\n",
      "chunks\n",
      "and\n",
      "adding\n",
      "them\n",
      "to\n",
      "the\n",
      "vector\n",
      "store.\n",
      "Querying\n",
      "the\n",
      "Vector\n",
      "Store\n",
      "○\n",
      "Implementing\n",
      "a\n",
      "loop\n",
      "to\n",
      "handle\n",
      "user\n",
      "queries.\n",
      "○\n",
      "Using\n",
      "the\n",
      "vector\n",
      "index\n",
      "to\n",
      "search\n",
      "for\n",
      "relevant\n",
      "documents.\n",
      "○\n",
      "Generating\n",
      "answers\n",
      "with\n",
      "the\n",
      "language\n",
      "model\n",
      "and\n",
      "displaying\n",
      "results.\n",
      "Summary:\n",
      "In\n",
      "this\n",
      "case\n",
      "study,\n",
      "you\n",
      "have\n",
      "explored\n",
      "the\n",
      "implementation\n",
      "of\n",
      "Retrieval- ...\"\n",
      "\n",
      "What's your next question (or type 'quit' to exit): Is case study outline available?\n",
      "\n",
      "QUESTION: \"Is case study outline available?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER: \"Yes, the case study outline is available in the provided context. It is listed under the \"Case Study Outline\" section and outlines the topics covered in the case study, including an introduction to RAG and LangChain, setting up the environment, data processing, implementing vector stores, and querying the vector store.\"\n",
      "\n",
      "FIRST DOCUMENTS BY RELEVANCE:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [0.8677] \"and\n",
      "contextually\n",
      "relevant\n",
      "responses.\n",
      "By\n",
      "completing\n",
      "this\n",
      "case\n",
      "study,\n",
      "you\n",
      "now\n",
      "have\n",
      "hands-on\n",
      "experience\n",
      "with\n",
      "the\n",
      "end-to-end\n",
      "process\n",
      "of\n",
      "setting\n",
      "up\n",
      "a\n",
      "RAG\n",
      "system\n",
      "using\n",
      "LangChain\n",
      "and\n",
      "AstraDB.\n",
      "This\n",
      "knowledge\n",
      "equips\n",
      "you\n",
      "with\n",
      "the\n",
      "skills\n",
      "to\n",
      "build\n",
      "more\n",
      "advanced\n",
      "and\n",
      "efﬁcient\n",
      "AI\n",
      "systems\n",
      "that\n",
      "leverage\n",
      "external\n",
      "data\n",
      "for\n",
      "improved\n",
      "performance.\n",
      "Proprietary\n",
      "content.\n",
      "©\n",
      "Great\n",
      "Learning.\n",
      "All\n",
      "Rights\n",
      "Reserved.\n",
      "Unauthorized\n",
      "use\n",
      "or\n",
      "distribution\n",
      "prohibited.\n",
      "3\n",
      "vinothiniveerasekar@gmail.com\n",
      "EGRWOTNAD8\n",
      "This file is meant for personal use by vinothiniveerasekar@gmail.com only.\n",
      "Sharing or publishing the contents in part or full is liable for legal action. ...\"\n",
      "    [0.8654] \"RAG\n",
      "with\n",
      "LangChain\n",
      "Day\n",
      "5\n",
      "Case\n",
      "Study:\n",
      "Learner\n",
      "Guide\n",
      "Objective\n",
      "In\n",
      "this\n",
      "case\n",
      "study,\n",
      "we\n",
      "will\n",
      "explore\n",
      "how\n",
      "to\n",
      "implement\n",
      "Retrieval-Augmented\n",
      "Generation\n",
      "(RAG)\n",
      "using\n",
      "LangChain,\n",
      "a\n",
      "powerful\n",
      "tool\n",
      "that\n",
      "integrates\n",
      "with\n",
      "AstraDB\n",
      "to\n",
      "enhance\n",
      "the\n",
      "capabilities\n",
      "of\n",
      "language\n",
      "models\n",
      "by\n",
      "incorporating\n",
      "external\n",
      "data.\n",
      "We\n",
      "will\n",
      "use\n",
      "OpenAI\n",
      "embeddings\n",
      "to\n",
      "convert\n",
      "text\n",
      "into\n",
      "vectors\n",
      "and\n",
      "leverage\n",
      "a\n",
      "vector\n",
      "store\n",
      "backed\n",
      "by\n",
      "AstraDB\n",
      "to\n",
      "store\n",
      "and\n",
      "query\n",
      "these\n",
      "vectors.\n",
      "Learning\n",
      "Outcomes:\n",
      "By\n",
      "the\n",
      "end\n",
      "of\n",
      "this\n",
      "case\n",
      "study,\n",
      "learners\n",
      "will\n",
      "be\n",
      "able\n",
      "to:\n",
      "●\n",
      "Understand\n",
      "the\n",
      "concept\n",
      "of\n",
      "Retrieval-Augmented\n",
      "Generation\n",
      "(RAG)\n",
      "and\n",
      "its\n",
      "applications.\n",
      "●\n",
      "Set\n",
      "up\n",
      "and\n",
      "conﬁgure\n",
      "LangChain\n",
      "with\n",
      "AstraDB\n",
      "for\n",
      "efﬁcient\n",
      "data\n",
      "retrieval\n",
      "and\n",
      "storage.\n",
      "●\n",
      "Implement\n",
      "a\n",
      "complete\n",
      "workﬂow\n",
      "to\n",
      "process\n",
      "documents,\n",
      "convert\n",
      "them\n",
      "into\n",
      "embeddings,\n",
      "and\n",
      "store\n",
      "them\n",
      "in\n",
      "a\n",
      "vector\n",
      "database.\n",
      "●\n",
      "Perform\n",
      "queries\n",
      "against\n",
      "the\n",
      "vector\n",
      "database\n",
      "and\n",
      "integrate\n",
      "the\n",
      "results\n",
      "with\n",
      "a\n",
      "language\n",
      "model\n",
      "to\n",
      "generate\n",
      "answers.\n",
      "Case\n",
      "Study\n",
      "Outline:\n",
      "Introduction\n",
      "to\n",
      "RAG\n",
      "and\n",
      "LangChain\n",
      "○\n",
      "Overview\n",
      "of\n",
      "RAG\n",
      "and\n",
      "its\n",
      "beneﬁ ...\"\n",
      "    [0.8537] \"●\n",
      "Setting\n",
      "Up\n",
      "LangChain\n",
      "and\n",
      "AstraDB:\n",
      "You\n",
      "successfully\n",
      "installed\n",
      "and\n",
      "conﬁgured\n",
      "the\n",
      "necessary\n",
      "libraries\n",
      "and\n",
      "established\n",
      "a\n",
      "connection\n",
      "with\n",
      "AstraDB\n",
      "using\n",
      "Cassio.\n",
      "This\n",
      "setup\n",
      "is\n",
      "crucial\n",
      "for\n",
      "managing\n",
      "and\n",
      "retrieving\n",
      "large-scale\n",
      "data\n",
      "efﬁciently.\n",
      "Proprietary\n",
      "content.\n",
      "©\n",
      "Great\n",
      "Learning.\n",
      "All\n",
      "Rights\n",
      "Reserved.\n",
      "Unauthorized\n",
      "use\n",
      "or\n",
      "distribution\n",
      "prohibited.\n",
      "2\n",
      "vinothiniveerasekar@gmail.com\n",
      "EGRWOTNAD8\n",
      "This file is meant for personal use by vinothiniveerasekar@gmail.com only.\n",
      "Sharing or publishing the contents in part or full is liable for legal action.\n",
      "●\n",
      "Data\n",
      "Processing:\n",
      "You\n",
      "practiced\n",
      "loading\n",
      "and\n",
      "extracting\n",
      "text\n",
      "data\n",
      "from\n",
      "a\n",
      "PDF\n",
      "document,\n",
      "converting\n",
      "it\n",
      "into\n",
      "embeddings\n",
      "using\n",
      "OpenAI,\n",
      "and\n",
      "storing\n",
      "these\n",
      "embeddings\n",
      "in\n",
      "a\n",
      "vector\n",
      "store\n",
      "backed\n",
      "by\n",
      "AstraDB.\n",
      "This\n",
      "process\n",
      "is\n",
      "fundamental\n",
      "for\n",
      "preparing\n",
      "data\n",
      "to\n",
      "be\n",
      "used\n",
      "in\n",
      "RAG.\n",
      "●\n",
      "Implementing\n",
      "Vector\n",
      "Stores:\n",
      "You\n",
      "created\n",
      "a\n",
      "LangChain\n",
      "vector\n",
      "store\n",
      "and\n",
      "wrapped\n",
      "it\n",
      "in\n",
      "a\n",
      "VectorStoreIndexWrapper,\n",
      "allowing\n",
      "for\n",
      "efﬁcient\n",
      "querying\n",
      "and\n",
      "retrieval\n",
      "of\n",
      "relevant\n",
      "documents\n",
      "based\n",
      "on\n",
      "user\n",
      "querie ...\"\n",
      "    [0.8530] \"Great\n",
      "Learning.\n",
      "All\n",
      "Rights\n",
      "Reserved.\n",
      "Unauthorized\n",
      "use\n",
      "or\n",
      "distribution\n",
      "prohibited.\n",
      "1\n",
      "vinothiniveerasekar@gmail.com\n",
      "EGRWOTNAD8\n",
      "This file is meant for personal use by vinothiniveerasekar@gmail.com only.\n",
      "Sharing or publishing the contents in part or full is liable for legal action.\n",
      "Data\n",
      "Retrieval\n",
      "and\n",
      "Preprocessing\n",
      "○\n",
      "Loading\n",
      "a\n",
      "dataset\n",
      "using\n",
      "HuggingFace.\n",
      "○\n",
      "Reading\n",
      "and\n",
      "extracting\n",
      "text\n",
      "from\n",
      "a\n",
      "PDF\n",
      "document.\n",
      "Connecting\n",
      "to\n",
      "AstraDB\n",
      "○\n",
      "Establishing\n",
      "a\n",
      "connection\n",
      "with\n",
      "AstraDB\n",
      "using\n",
      "Cassio.\n",
      "○\n",
      "Conﬁguring\n",
      "database\n",
      "credentials\n",
      "and\n",
      "tokens.\n",
      "Embedding\n",
      "and\n",
      "Storing\n",
      "Data\n",
      "○\n",
      "Creating\n",
      "LangChain\n",
      "embeddings\n",
      "using\n",
      "OpenAI.\n",
      "○\n",
      "Setting\n",
      "up\n",
      "a\n",
      "LangChain\n",
      "vector\n",
      "store\n",
      "backed\n",
      "by\n",
      "AstraDB.\n",
      "○\n",
      "Splitting\n",
      "text\n",
      "into\n",
      "chunks\n",
      "and\n",
      "adding\n",
      "them\n",
      "to\n",
      "the\n",
      "vector\n",
      "store.\n",
      "Querying\n",
      "the\n",
      "Vector\n",
      "Store\n",
      "○\n",
      "Implementing\n",
      "a\n",
      "loop\n",
      "to\n",
      "handle\n",
      "user\n",
      "queries.\n",
      "○\n",
      "Using\n",
      "the\n",
      "vector\n",
      "index\n",
      "to\n",
      "search\n",
      "for\n",
      "relevant\n",
      "documents.\n",
      "○\n",
      "Generating\n",
      "answers\n",
      "with\n",
      "the\n",
      "language\n",
      "model\n",
      "and\n",
      "displaying\n",
      "results.\n",
      "Summary:\n",
      "In\n",
      "this\n",
      "case\n",
      "study,\n",
      "you\n",
      "have\n",
      "explored\n",
      "the\n",
      "implementation\n",
      "of\n",
      "Retrieval- ...\"\n",
      "\n",
      "What's your next question (or type 'quit' to exit): quit\n"
     ]
    }
   ],
   "source": [
    "first_question = True\n",
    "while True:\n",
    "    if first_question:\n",
    "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
    "    else:\n",
    "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
    "\n",
    "    if query_text.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    if query_text == \"\":\n",
    "        continue\n",
    "\n",
    "    first_question = False\n",
    "\n",
    "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
    "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
    "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
    "\n",
    "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
    "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuOfm8zbvOEa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
